sumInfect<-sum(big_out$IncI)
sumInfect
#sum(big_out$L_tot * params[names(params) == "sigma"] )
# Outbreak duration (when no new cases)
big_out$cumI<-NA
big_out$cumI[1]<-big_out$IncI[1]
for(i in 2:n)
big_out$cumI[i] <- (big_out$IncI[i] +big_out$cumI[i-1])
matplot(x = big_out[,c("time")], y = big_out[,c('cumI')], type = "l",
xlab = "Time", ylab = "individuals", main = "Cumulative incidence",
lwd = 2, lty = 1, bty = "l", col = 6)
datemaxCumI<-big_out$time[big_out$cumI==max(big_out$cumI)]
min(datemaxCumI)
# Attack rate
AR <- sumInfect*100/(37600000+200)
AR
### Hospitalized
big_out$Hosp <- big_out$I_ssh
matplot(x = big_out[,c("time")], y = big_out[,c('Hosp')], type = "l",
xlab = "Time", ylab = "individuals", main = "Hospitalized",
lwd = 2, lty = 1, bty = "l", col = 3)
maxHosp<-max(big_out$Hosp)
maxHosp<-max(big_out$I_ssh)
maxHosp
datemaxHosp<-big_out$time[big_out$Hosp==max(big_out$Hosp)]
datemaxHosp
#total number of hopitalized
big_out$newH<-NA
big_out$newH[1]<-big_out$I_ssh[1]
for(i in 2:300)
big_out$newH[i] <-
(
big_out$I_ss[i-1] + big_out$I_ssr[i-1])*
(curr_param$value[curr_param$name=='kappa'])*
(curr_param$value[curr_param$name=='feish']) +
(curr_param$value[curr_param$name=='delta'])*
(1-curr_param$value[curr_param$name=='alpha'])*
(curr_param$value[curr_param$name=='epsilonq'])*
big_out$I_aq[i-1]
big_out$I_ssh %>% plot()
sum(big_out$newH, na.rm = T)
big_out$newH2<-NA
big_out$newH2[1]<-big_out$I_ssh[1]
for(i in 2:300){
big_out$newH2[i]<-big_out$I_ssh[i-1]*
((1-(curr_param$value[curr_param$name=='mu']))*
(curr_param$value[curr_param$name=='nus']) +
(curr_param$value[curr_param$name=='mu'])*
(curr_param$value[curr_param$name=='nud']))
}
sum(big_out$newH2, na.rm = T)
sum(big_out$newH2, na.rm = T)/sum(big_out$IncI)
#######Number of death
max(big_out$D)
#### Quarantined
big_out$Quarant <- big_out$I_aq
matplot(x = big_out[,c("time")], y = big_out[,c('Quarant')], type = "l",
xlab = "Time", ylab = "individuals", main = "Quarantined",
lwd = 2, lty = 1, bty = "l", col = 4)
#legend(250, 1000000, c("Hospitalized"), pch = 1, col = 3, bty = "n")
maxQuarant<-max(big_out$Quarant)
maxQuarant
datemaxQuarant<-big_out$time[big_out$Quarant==max(big_out$Quarant)]
datemaxQuarant
##### Isolated
big_out$Isolat <- big_out$I_smis + big_out$I_ssis
matplot(x = big_out[,c("time")], y = big_out[,c('Isolat')], type = "l",
xlab = "Time", ylab = "individuals", main = "Isolated",
lwd = 2, lty = 1, bty = "l", col = 5)
maxIsolat<-max(big_out$Isolat)
maxIsolat
datemaxIsolat<-big_out$time[big_out$Isolat==max(big_out$Isolat)]
datemaxIsolat
# dI <- sigma*rho*L - (delta_I*(1-omega) +  gamma_I*omega)*I + mu*epsilon*A
# dA <- sigma*(1 - rho)*L - (1-epsilon)*gamma_A*A - mu*epsilon*A
###################################################################################################
epsilon  <-params['epsilon']
LOG_FILE_BASE_NAME = paste0("SEIR_LOG_", Sys.Date())
time_param_names <-
time_stuff %>%
select(-tmin, -tmax) %>%
colnames()
#################################################################################################
### User input for the initial conditions
time_stuff <- read_excel("c:/users/joel/google drive/github/seir/input_sheet_5agegrp.xls",
sheet = "time")
time_param_names <-
time_stuff %>%
select(-tmin, -tmax) %>%
colnames()
warnings()
time_stuff <- time_stuff %>%
mutate(t_n = tmax - tmin) %>%
mutate(., isim = 1:nrow(.))
all_param <- time_stuff %>% pivot_longer(cols = time_param_names)
input_stuff <- read_excel("c:/users/joel/google drive/github/seir/input_sheet_5agegrp.xls",
sheet = "input")
init <- as.integer(input_stuff$VALUE)
names(init) <- input_stuff$NAME
nSim <- nrow(time_stuff)
init <- as.integer(input_stuff$VALUE)
library(deSolve)
library(ggplot2)
library(tidyr)
library(dplyr)
library(tidyverse)
library(matrixStats)
library(readxl)
library(janitor)
LOG_FILE_BASE_NAME = paste0("SEIR_LOG_", Sys.Date())
#################################################################################################
### User input for the initial conditions
time_stuff <- read_excel("c:/users/joel/desktop/phac/input_sheet SC3 beta0.167.xlsx",
sheet = "time")
time_param_names <-
time_stuff %>%
select(-tmin, -tmax) %>%
colnames()
time_stuff <- time_stuff %>%
mutate(t_n = tmax - tmin) %>%
mutate(., isim = 1:nrow(.))
all_param <- time_stuff %>% pivot_longer(cols = time_param_names)
input_stuff <- read_excel("c:/users/joel/desktop/phac/input_sheet SC3 beta0.167.xlsx",
sheet = "input")
init <- as.integer(input_stuff$VALUE)
names(init) <- input_stuff$NAME
nSim <- nrow(time_stuff)
seir <- function(time, state, parms) {
with(as.list(c(state, parms)), {
dS <- -beta*((c*(1-lambda)*tau)+(cq*lambda)+(cr*(1-lambda)*(1-tau)))*S*(I_a + I_aqn + I_sm + I_ss + I_smisn + I_ssisn+I_ar+I_smr+I_ssr+I_smrisn+I_ssrisn+phi*I_aq)
dL <- (1-lambda)*beta*c*tau*S*(I_a + I_aqn + I_sm + I_ss + I_smisn + I_ssisn+I_ar+I_smr+I_ssr+I_smrisn+I_ssrisn+phi*I_aq) - sigma*L
dL_q <- lambda*beta*cq*S*(I_a + I_aqn + I_sm + I_ss + I_smisn + I_ssisn+I_ar+I_smr+I_ssr+I_smrisn+I_ssrisn+phi*I_aq) - sigma*L_q
dL_r <-  beta*cr*(1-lambda)*(1-tau)*S*(I_a + I_aqn + I_sm + I_ss + I_smisn + I_ssisn+I_ar+I_smr+I_ssr+I_smrisn+I_ssrisn+phi*I_aq)-sigma*L_r
dI_a <- sigma*L - I_a*delta*epsilon - I_a*(1-delta)*upsilon
dI_aq <- sigma*rho*L_q - I_aq*delta*epsilonq - I_aq*(1-delta)*upsilon
# dI_aq <- sigma*rho*L_q - I_aq*delta*epsilon - I_aq*(1-delta)*upsilon
dI_ar <- sigma*L_r - I_ar*delta*epsilon - I_ar*(1-delta)*upsilon
dI_aqn <- sigma*(1-rho)*L_q - I_aqn*delta*epsilon - I_aqn*(1-delta)*upsilon
#dI_sm <- (I_a)*delta*epsilon*alpha - kappa*I_sm
dI_sm <- (I_a+I_aqn)*delta*epsilon*alpha - kappa*I_sm
#dI_ss <- I_a*delta*epsilon*(1-alpha) - kappa*I_ss
dI_ss <- (I_a+I_aqn)*delta*epsilon*(1-alpha) - kappa*I_ss
dI_smr <- I_ar*delta*epsilon*alpha - kappa*I_smr
dI_ssr <- I_ar*delta*epsilon*(1-alpha) - kappa*I_ssr
dI_smis <- kappa*feim*I_sm + kappa*feimr*I_smr + delta*alpha*epsilonq*feimq*I_aq - num*I_smis
dI_smisn <- kappa*(1-feim)*I_sm - num*I_smisn
dI_ssis <- kappa*feisi*(I_ss+I_ssr) - I_ssis*((1-mu)*nus + mu*nud)
#dI_ssisn <- kappa*(1-feisi-feish)*(I_ss+I_ssr) - I_ssisn*((1-mu)*nus + mu*nud)
dI_ssisn <- kappa*(1-feisi-feish)*(I_ss) - I_ssisn*((1-mu)*nus + mu*nud)
dI_ssh <- kappa*feish*(I_ss+I_ssr) + delta*(1-alpha)*epsilonq*I_aq - I_ssh*((1-mu)*nus + mu*nud)
dI_smrisn <- kappa*(1-feimr)*I_smr - num*I_smrisn
dI_ssrisn <- kappa*(1-feisi-feish)*(I_ssr) - I_ssrisn*((1-mu)*nus + mu*nud)
dI_smqisn <- I_aq*delta*alpha*epsilonq*(1-feimq) - num*I_smqisn
dR <- (I_a +I_aq+I_aqn+I_ar)*(1-delta)*upsilon + num*(I_smis+I_smisn+I_smqisn+I_smrisn) + (I_ssis + I_ssisn + I_ssh+I_ssrisn)*(1-mu)*nus
dD <- mu*nud*(I_ssis + I_ssisn + I_ssh + I_ssrisn)
return(list(c(dS, dL, dL_q, dL_r, dI_a, dI_aq, dI_ar, dI_aqn, dI_sm, dI_ss,dI_smr, dI_ssr, dI_smis, dI_smisn, dI_ssis, dI_ssisn, dI_ssh, dI_smrisn, dI_ssrisn, dI_smqisn, dR, dD)))  })
}#
#################################################################################################
# Simulation
# Create list to store model output
listOut <- NULL
listOut <- list()
i=1
for(i in seq(1, nSim, 1)){
### Set time frame in days
t <- seq(0, time_stuff$t_n[i], by = 1)
curr_param <- all_param %>% filter(isim == i)
params <- curr_param$value
names(params) <- curr_param$name
##########################################
#
#
# This is an example of how to dynamically set params based on conditions for SEIR state
# It is not elegant and it will override the input file but it should work
#
#print(paste0("i = ", i))
#print(paste0("beta First = ", params[names(params) == "beta"]))
# *********************************************
#    ***** EXAMPLE DYNAMIC VARIABLES ****
#params[names(params) == "beta"]  <- 0.05 / init[names(init) == "S"]
#print(paste0("beta after = ", params[names(params) == "beta"]))
#####################################
#all(params == old_params)
#all(names(params) == names(old_params))
#all(init == old_init)
#all(names(init) == names(old_init))
#all(t == old_t)
### Run the model
out <- ode(y = init,
times = t,
func = seir,
parms = params
)
#rowSums(out) %>% plot()
out <- out %>%
as_tibble() #%>% mutate_all(.funs = as.integer)
out %>% write.csv(paste0(LOG_FILE_BASE_NAME,"_i-" ,i, ".csv"))
out <- out #%>% mutate_all(as.integer)
out$time <- seq(time_stuff$tmin[i], time_stuff$tmax[i], 1)
# Add model output to list
listOut[[i]] <- out
out_for_init <-
out %>%
slice(nrow(out)) %>%
pivot_longer(-time)
#init <- as.integer(out_for_init$value)
init <-out_for_init$value
names(init) <- out_for_init$name
}
big_out <- bind_rows(listOut) %>% distinct()
big_out %>% write.csv(paste0(LOG_FILE_BASE_NAME,"_big_out-" ,i, ".csv"))
shiny::runApp('C:/Users/Joel/Google Drive/GitHub/SEIR')
runApp('C:/Users/Joel/Google Drive/GitHub/SEIR')
?all_of
runApp('C:/Users/Joel/Google Drive/GitHub/SEIR')
library(tidyselect)
runApp('C:/Users/Joel/Google Drive/GitHub/SEIR')
runApp('C:/Users/Joel/Google Drive/GitHub/SEIR')
library(abind)
detach("package:abind", unload = TRUE)
install.packages("tidyselect")
install.packages("tidyselect")
library(tidyselect)
install.packages("tidyselect")
library("tidyselect")
library(tidyverse)
remove.packages("tidyselect", lib="~/R/win-library/3.6")
install.packages("tidyselect")
install.packages("tidyselect")
library(tidyselect)
library("tidyselect")
# Load packages to extend base R
package_names <- c("janitor","readxl","dplyr","deSolve","tidyr","ggplot2", "ggpubr", "tidyverse", "shiny", "shinycssloaders", "DT", "scales", "plotly", "matrixcalc")
load_packages <- lapply(package_names, require, character.only = TRUE)
install.packages("C:/Users/Joel/Downloads/tidyselect_1.0.0.tar.gz", repos = NULL, type = "source")
library("tidyselect")
install.packages("tidyselect")
shiny::runApp('C:/Users/Joel/Desktop/demo')
runApp('C:/Users/Joel/Desktop/demo')
runApp('C:/Users/Joel/Desktop/demo')
runApp('C:/Users/Joel/Google Drive/GitHub/SEIR/robots_v4')
WDir <- "c:/users/joel/google drive/github/seir/claude_v6"
setwd(WDir)
source("UtilitiesChunks.R")
source("SEIR.n.Age.Classes.R")
file_name   = file.path(WDir,"covid19_input_sheet_v4(5agegrp - old names).xls")
sheet_names_v2 = list(initial.conditions="Initial conditions",parms.1d="Parameters by Age",parms.2d="Parameters by Age x Age",model.flow="Model Specs v2",auxiliary.vars="Intermediate calculations")
# note that 3rd argument (i.e. seq(0,1499,1) here) is currently inoperant
results.sheet.v1.bad  = SEIR.n.Age.Classes(file_name,sheet_names_v1,seq(0,1499,1) ) # scale.rate.to.size  FALSE by default now
results.sheet.v1.good = SEIR.n.Age.Classes(file_name,sheet_names_v1,seq(0,1499,1), scale.rate.to.size=TRUE )
results.sheet.v2.good = SEIR.n.Age.Classes(file_name,sheet_names_v2,seq(0,1499,1) ) # scale.rate.to.size  FALSE by default now
results.sheet.v2.bad  = SEIR.n.Age.Classes(file_name,sheet_names_v2,seq(0,1499,1), scale.rate.to.size=TRUE )
rm(list = ls())
WDir <- "c:/users/joel/google drive/github/seir/claude_v6"# working directory **** NO TRAILING /   akin to choose.dir()  ****
setwd(WDir)
getwd()    # show working directory
source("UtilitiesChunks.R")
source("SEIR.n.Age.Classes.R")
file_name   = file.path(WDir,"BluePrint2 PHAC material posted on Slack on April 13(1agegrp).xls")
sheet_names = list(initial.conditions="Initial conditions",parms.1d="Parameters by Age",parms.2d="Parameters by Age x Age",model.flow="Model Specs",auxiliary.vars="Intermediate calculations")
sheet_names$scale.rate.to.size = FALSE  # reminder that sheet_names$model.flow is constructed in such a way that it calls for scale.rate.to.size = FALSE
results.1 = SEIR.n.Age.Classes(file_name,sheet_names,  scale.rate.to.size = sheet_names$scale.rate.to.size )
l
#  compare out with results.1
range(results.1$solution$time)  # 0 149
results.1 = SEIR.n.Age.Classes(file_name,sheet_names,  scale.rate.to.size = sheet_names$scale.rate.to.size )
file_name   = file.path(WDir,"BluePrint2 PHAC material posted on Slack on April 13(1agegrp).xls")
sheet_names = list(initial.conditions="Initial conditions",parms.1d="Parameters by Age",parms.2d="Parameters by Age x Age",model.flow="Model Specs",auxiliary.vars="Intermediate calculations")
sheet_names$scale.rate.to.size = FALSE  # reminder that sheet_names$model.flow is constructed in such a way that it calls for scale.rate.to.size = FALSE
results.2 = SEIR.n.Age.Classes(file_name,sheet_names,  scale.rate.to.size = sheet_names$scale.rate.to.size )
results.1 = SEIR.n.Age.Classes(file_name,sheet_names,  scale.rate.to.size = sheet_names$scale.rate.to.size )
shiny::runApp('C:/Users/Joel/Google Drive/GitHub/SEIR/claude_v6')
runApp('C:/Users/Joel/Google Drive/GitHub/SEIR/claude_v6')
runApp('C:/Users/Joel/Google Drive/GitHub/SEIR/claude_v6')
runApp('C:/Users/Joel/Google Drive/GitHub/SEIR/claude_v6')
runApp('C:/Users/Joel/Google Drive/GitHub/SEIR/claude_v6')
runApp('C:/Users/Joel/Google Drive/GitHub/SEIR/claude_v6')
runApp('C:/Users/Joel/Google Drive/GitHub/SEIR/claude_v6')
runApp('C:/Users/Joel/Google Drive/GitHub/SEIR/claude_v6')
runApp('C:/Users/Joel/Google Drive/GitHub/SEIR/claude_v6')
rm(list = ls())
rm(list = ls())
package_names <- c("janitor","readxl","dplyr","deSolve","tidyr","ggplot2", "ggpubr", "tidyverse", "viridis")
load_packages <- lapply(package_names, require, character.only = TRUE)
WDir <- "C:/joel/google drive/github/seir/claude_v6"# working directory **** NO TRAILING /   akin to choose.dir()  ****
setwd(WDir)
getwd()    # show working directory
rm(list = ls())
library(deSolve)
library(ggplot2)
library(tidyr)
library(dplyr)
library(tidyverse)
library(matrixStats)
library(readxl)
library(janitor)
source("SEIR_util.r")
library(deSolve)
library(ggplot2)
library(tidyr)
library(dplyr)
library(tidyverse)
library(matrixStats)
library(readxl)
library(janitor)
setwd("c:/users/joel/desktop/phac2")
source("SEIR_util.r")
G_FN <- "input_sheet_tst.xlsx"
####################################
#
read_input <- function(fn = G_FN) {
param_df <- readxl::read_excel(G_FN, sheet = "param")
param_df$typ <- "param"
init_df <- readxl::read_excel(G_FN, sheet = "init")
init_df$typ <- "state"
mdl_df <- rbind(param_df, init_df)
return(mdl_df)
}
####################################
run_mdl <- function(fn = G_FN, overrides = NULL){
mdl_df <- read_input(fn = fn)
for (nm in names(overrides)){
mdl_df %>% filter(name == nm ) %>%
mutate()
mdl_df <-
mdl_df %>%
mutate(value = replace(value, name == nm, overrides[[nm]]))
}
mdl_lst <- NULL
#mdl_lst <- as.list(mdl_df$value) %>% setNames(mdl_df$name)
state_df <- mdl_df %>% filter(typ == "state")
state_vec <- state_df$value %>% set_names(state_df$name)
state_vec %>% length()
param_df <- mdl_df %>% filter(typ == "param")
param_lst <- as.list(param_df$value) %>% setNames(param_df$name)
Times <- 1:param_lst$max_time_steps
out <- deSolve::ode(y = state_vec,
times = Times,
func = seir,
parms = param_lst
) %>% as_tibble() %>%
mutate_all(as.numeric) %>%
calc_agg()
out <- out %>% cbind(param_df %>% select(name, value) %>% pivot_wider(names_from = name, values_from = value)) %>% as_tibble()
out_delta <-
out %>%
calc_all_Ds(D_to_calc = D_to_update, ignore_out = TRUE, ignore_in = FALSE)
out <-cbind(out, out_delta) %>% as_tibble()
return(out)
}
##################################
#
calc_agg_pattern <- function(df, pattern = "^L", fun = rowSums){
df %>% select(matches(pattern)) %>% fun
}
#################################
#
calc_agg <- function(df = out,
t = "time",
cols = df  %>% select(-t) %>% colnames(),
fun = rowSums,
fun_nm = "rowSums",
col_prefix = "AGG",
sep = "_"
){
df$AGG_TOTAL_PEOPLE <- df %>% select(-t) %>% rowSums()
df[[paste(col_prefix, "L", fun_nm, sep = sep)]] <- df %>% calc_agg_pattern("^L", fun = fun)
df[[paste(col_prefix, "I", fun_nm, sep = sep)]] <- df %>% calc_agg_pattern("^I", fun = fun)
df[[paste(col_prefix, "S", fun_nm, sep = sep)]] <- df %>% calc_agg_pattern("^S", fun = fun)
df[[paste(col_prefix, "R", fun_nm, sep = sep)]] <- df %>% calc_agg_pattern("^R", fun = fun)
df[[paste(col_prefix, "D", fun_nm, sep = sep)]] <- df %>% calc_agg_pattern("^D", fun = fun)
df[[paste(col_prefix, "H", fun_nm, sep = sep)]] <- df %>% calc_agg_pattern("^H", fun = fun)
return(df)
}
#################################
##
find_peaks <- function(df = out,
t = "time",
cols = df  %>% select(-t) %>% colnames()
){
df %>%
select(t, cols) %>%
pivot_longer(cols = -time) %>%
group_by(name) %>%
slice(which.max(value)) %>%
arrange(time)
}
########################################
# Run the model and get the output.
out <- run_mdl()
library(xlsx)
out$AGG_TOTAL_PEOPLE
###############################33
#output the peaks of any column
out %>% find_peaks()
#####################################3
#get the people that go through a given box
out %>% select(time, matches("^CHANGE_")) %>%
pivot_longer (matches("^CHANGE_")) %>%
group_by(name) %>%
summarise(value = sum(value))
# Show the death rate, hospitalization and Severe symptoms
out %>%
select(time, Hg, D, Issq) %>%
pivot_longer(cols = -time) %>%
ggplot(aes(x = time, y = value, color = name)) + geom_line(size = 1.5) + theme_bw()
out$AGG
out %>% select(matches("^AGG_"), time) %>% select(-AGG_TOTAL_PEOPLE) %>%
pivot_longer(cols = matches("^AGG_")) %>%
ggplot(aes(x = time, y = value, color = name)) +
geom_line(size = 1.5) +
#scale_y_log10() +
#annotation_logticks(sides = "l")+
labs(title = "Major desease compartments against time", y = "Number of People", x = "Time") +
theme_bw()
ggplotly(p)
str(out)
write.csv(out, "c:/users/joel/desktop/phac2/seir_3_out.csv", row.names = FALSE, na = "")
rm(list = ls())
package_names <- c("janitor","readxl","dplyr","deSolve","tidyr","ggplot2", "ggpubr", "tidyverse", "viridis")
load_packages <- lapply(package_names, require, character.only = TRUE)
WDir <- "c:/users/joel/google drive/github/seir/claude_v6"
setwd(WDir)
getwd()    # show working directory
source("UtilitiesChunks.R")
source("SEIR.n.Age.Classes.R")
file_name   = file.path(WDir,"BluePrint2 PHAC material posted on Slack on April 13(1agegrp).xls")
sheet_names = list(initial.conditions="Initial conditions",parms.1d="Parameters by Age",parms.2d="Parameters by Age x Age",model.flow="Model Specs",auxiliary.vars="Intermediate calculations")
sheet_names$scale.rate.to.size = FALSE  # reminder that sheet_names$model.flow is constructed in such a way that it calls for scale.rate.to.size = FALSE
results.1 = SEIR.n.Age.Classes(file_name,sheet_names,  scale.rate.to.size = sheet_names$scale.rate.to.size )
#  compare out with results.1
range(results.1$solution$time)  # 0 149
range(out$time)  #  1 150
source("seir_3_out.csv")
out <- read.csv("seir_3_out.csv")
range(out$time)  #  1 150
range(diff(results.1$solution$time)) # 1 1  --> times are in 1 unit increments
range(diff(out$time))                # 1 1  --> times are in 1 unit increments
shared.names = setdiff(intersect(colnames(results.1$solution),colnames(out)),"time")
range( out[,shared.names] - results.1$solution[,shared.names]) # -0.3152966   0.3074130 some absolute differences
range((out[,shared.names] - results.1$solution[,shared.names])/ (1e-9+ pmax(out[,shared.names] , results.1$solution[,shared.names]) ) ) #  -5.145957e-06  3.020563e-06 smallish relative differences
range((out[,shared.names] - results.1$solution[,shared.names])/ (1e-9+ pmin(out[,shared.names] , results.1$solution[,shared.names]) ) ) #  -5.145983e-06  3.020573e-06 smallish relative differences
file_name   = file.path(WDir,"BluePrint2 PHAC material posted on Slack on April 13(1agegrp).xls")
sheet_names = list(initial.conditions="Initial conditions",parms.1d="Parameters by Age",parms.2d="Parameters by Age x Age",model.flow="Model Specs",auxiliary.vars="Intermediate calculations")
sheet_names$scale.rate.to.size = FALSE  # reminder that sheet_names$model.flow is constructed in such a way that it calls for scale.rate.to.size = FALSE
results.2 = SEIR.n.Age.Classes(file_name,sheet_names,  scale.rate.to.size = sheet_names$scale.rate.to.size )
range( results.2$solution  - results.1$solution ) # -900.8799  900.8475
range( results.2$input.info$parms.1d$Hg_cap ) # 10000  10000  --> max capacity is 10000
max(results.1$solution$Hg)                    #  9259.262     --> does not use  all capacity
max(results.2$solution$Hg)                    # 10000.29      -->          uses all capacity
matplot(results.2$solution$time, cbind(results.1$solution$Hg,results.2$solution$Hg))
file_name   = file.path(WDir,"BluePrint2 PHAC material posted on Slack on April 13(5agegrp).xls")
sheet_names = list(initial.conditions="Initial conditions",parms.1d="Parameters by Age",parms.2d="Parameters by Age x Age",model.flow="Model Specs",auxiliary.vars="Intermediate calculations")
sheet_names$scale.rate.to.size = FALSE  # reminder that sheet_names$model.flow is constructed in such a way that it calls for scale.rate.to.size = FALSE
results.5ages = SEIR.n.Age.Classes(file_name,sheet_names,  scale.rate.to.size = sheet_names$scale.rate.to.size )
range(results.5ages$solution$N_tot) # 1000100 1000100  rien ne se perd, rien ne se crée, tout se transforme
range(results.2$solution$N_tot)     # 1000100 1000100  rien ne se perd, rien ne se crée, tout se transforme
for(this.box in setdiff(colnames(results.2$solution),c( "time","N_tot" )) )
{
somme = apply(results.5ages$solution[,paste0(this.box,1:5)],1,sum)
cat("\n",this.box, range(results.2$solution[,this.box] - somme) )   # fairly good agreement between results.2 and results.5ages
}
matplot(results.5ages$solution$time,results.5ages$solution[,paste0("Sg",1:5)],type="l",xlab="time") # plotting without ggplot2 just like a dynosaur.
# END 3) test with 5 age groups
# BEGIN 4) parameter sweep with example 2)
file_name   = file.path(WDir,"BluePrint2 PHAC material posted on Slack on April 13(1agegrp).xls")
sheet_names = list(initial.conditions="Initial conditions",parms.1d="Parameters by Age",parms.2d="Parameters by Age x Age",model.flow="Model Specs",auxiliary.vars="Intermediate calculations")
sheet_names$scale.rate.to.size = FALSE  # reminder that sheet_names$model.flow is constructed in such a way that it calls for scale.rate.to.size = FALSE
sheet_names_for_sweep = sheet_names        # provide sheet names used in results (results.sheet.v2.good)
baseline.parms.1d = results.2$input.info$parms.1d  # data frame of 1d parameters
list.sweep = list() #        store results in list  ...
df.sweep = c()      # ... or store results in data.frame
for(log.fudge.factor in seq(-0.5,0.5,0.25))
{
cat("\n Doing log.fudge.factor=",log.fudge.factor)
this.label = paste("sigma multiplied by",exp(log.fudge.factor))
parms.1d = baseline.parms.1d  # data frame of 1d parameters
parms.1d$t_latency = parms.1d$t_latency * exp(log.fudge.factor) # alter t_latency as per parameter sweep
sheet_names_for_sweep$parms.1d = parms.1d
this.result = SEIR.n.Age.Classes(file_name,sheet_names_for_sweep, scale.rate.to.size = sheet_names$scale.rate.to.size )
list.sweep[[this.label]] = this.result$solution
this.result$solution$this.label = this.label
df.sweep = rbind(df.sweep,this.result$solution)
}
range(list.sweep$"sigma multiplied by 1" - results.2$solution) # same      as expected
range(list.sweep[[ 3 ]]                  - results.2$solution) # same      as expected
range(list.sweep[[ 2 ]]                  - results.2$solution) # different as expected
extract.df = subset(df.sweep,this.label == "sigma multiplied by 1")
extract.df$this.label = c()
range(extract.df - results.2$solution)
plot(subset(df.sweep,time<50)$time , subset(df.sweep,time<50)$Sg,type="l") # quick crack at plotting. Can do much better ...
results = results.5ages
listOut = results$listOut.to.be.decomissioned
nagegrp = ncol(results$input.info$initial.conditions)-1
# Define packages
package_names <- c("sjPlot", "tidyverse")
# Install packages if they haven't been installed previously
install_packages <- lapply(package_names, FUN = function(x) if(! require(x, character.only = TRUE)) install.packages(x))
# Load packages
load_packages <- lapply(package_names, require, character.only = TRUE)
library(sjstats)
library(sjmisc)
library(sjlabelled)
install.packages(c("sjlabelled", "sjmisc", "sjPlot", "sjstats"))
# Define packages
package_names <- c("lme4", "sjPlot", "tidyverse")
# Install packages if they haven't been installed previously
install_packages <- lapply(package_names, FUN = function(x) if(! require(x, character.only = TRUE)) install.packages(x))
# Load packages
load_packages <- lapply(package_names, require, character.only = TRUE)
setwd("c:/users/joel/google drive/github/hoffman")
getwd()
